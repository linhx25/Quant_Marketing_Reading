### ~reading
- Syllabus_RSM_Avi

### 20240509_directionPreferenceOptimization
- Understanding Contrastive Learning via Distributionally Robust Optimization
- RLPROMPT- Optimizing Discrete Text Prompts with Reinforcement Learning
- Iterative Preference Learning from Human Feedback- Bridging Theory and Practice for RLHF under KL-Constraint
- Is DPO Superior to PPO for LLM Alignment- A Comprehensive Study
- From r to Q∗ - Your Language Model is Secretly a Q-Function
- Distributionally Robust Optimization- A Review
- Direct Preference Optimization- Your Language Model is Secretly a Reward Model
- A note on DPO with noisy preferences & relationship to IPO
- A General Theoretical Paradigm to Understand Learning from Human Preferences

### 20240308_diffusion
- Neural Network Diffusion

### 20240222_fin_decision_making
- Consumer Financial Decision Making-Where We ve Been and Where We -re Going

### 20240217_rlhf_and_causal_inference
- Policy learning with observational data
- Optimizing Language Models for Human Preferences is a Causal Inference Problem
- Do Transformers Really Perform Bad for Graph Representation
- Conservative Q-Learning for Offline Reinforcement Learning
- Choice Models and Permutation Invariance- Demand Estimation in Differentiated Products Markets
- Causal Transformer for Estimating Counterfactual Outcomes
- CAUSAL ESTIMATION FOR TEXT DATA WITH (APPARENT) OVERLAP VIOLATIONS
- BENCHMARKS FOR DEEP OFF-POLICY EVALUATION

### 20240125_creativityLLM
- When ChatGPT is gone- Creativity reverts and homogeneity persists
- Uncertainty in Language Models- Assessment through Rank-Calibration
- Training language models to follow instructions with human feedback
- Measuring Divergent Thinking Originality With Human Raters and TextMining Models- A Psychometric Comparison of Methods
- DOES WRITING WITH LANGUAGE MODELS REDUCE CONTENT DIVERSITY
- Computational Creativity and Music Generation Systems
- Beyond semantic distance- Automated scoring of divergent thinking greatly improves with large language models 

### 20240117_structural
- Structural Econometric Modeling in Industrial Organization and Quantitative Marketing_ Theory and Applications (2023)
- Nonparametric Estimation of Habitual Brand Loyalty
- Estimating Parameters of Structural Models Using Neural Networks
- Deep Neural Networks for Estimation and Inference
- Causal Interpretation of Structural IV Estimands

### 20231212_LLM
- coauthor-Designing a Human-AI Collaborative Writing Dataset for Exploring Language Model Capabilities
- The Power of Scale for Parameter-Efficient Prompt Tuning
- TRUSTLLM- TRUSTWORTHINESS IN LARGE LANGUAGE MODELS
- Stanford_Speech and Language Processing
- Learning Decomposed Spatial Relations for Multi-Variate Time-Series Modeling
- LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS
- Deep Learning-based Estimation of Dynamic Discrete Choice Models with an Application to the Expansion of Walmart
- DECODINGTRUST- A Comprehensive Assessment of Trustworthiness in GPT Models
- Can LLMs Capture Human Preferences
- Alleviating Hallucinations of Large Language Models through Induced Hallucinations
- A Survey on Hallucination in Large Language Models

### 20231129_cb_fariness
- xia-et-al-2004-the-price-is-unfair-a-conceptual-framework-of-price-fairness-perceptions
- liu-et-al-2023-algorithm-aversion-evidence-from-ridesharing-drivers
- Perceptions of Price Unfairness Antecedents and Consequesnces
- Fairness as a Constraint on Profit Seeking- Entitlements in the Market
- Dynamic Pricing and Consumer Fairness Perceptions
- Consumer Perceptions of Price (Un)Fairness
- Algorithms propagate gender bias in the marketplace with consumers cooperation

### 20231121_RLHF
- malika_draft_jmp
- Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback
- The Challenge of Using LLMs to Simulate Human Behavior- A Causal Inference Perspective
- Secrets of RLHF in Large Language Models Part I- PPO
- STATISTICAL REJECTION SAMPLING IMPROVES PREFERENCE OPTIMIZATION
- Q-Transformer- Scalable Offline Reinforcement Learning via Autoregressive Q-Functions
- Policy Optimization in RLHF- The Impact of Out-of-preference Data
- Is RLHF More Difficult than Standard RL
- Inverse Reinforcement Learning with Conditional Choice Probabilities
- Defining and Characterizing Reward Hacking
- Deep reinforcement learning from human preferences
- Contrastive Preference Learning- Learning from Human Feedback without RL
- Chain-of-Thought Prompting Elicits Reasoning in Large Language Models
- Better Planning with Transformers via Search Dynamics Bootstrapping
- A Course in Reinforcement Learning

### 20231115_consumersearch
- a model of price adjustment
- Which demand systems can be generated by discrete choice
- Varian-ModelSales-1980

### 20231101_hallucination
- TruthfulQA- Measuring How Models Mimic Human Falsehoods
- On the Creativity of Large Language Models
- On Characterizations of Large Language Models and Creativity Evaluation
- Llama 2- Open Foundation and Fine-Tuned Chat Models
- Inspecting and Editing Knowledge Representations in Language Models
- Art or Artifice Large Language Models and the False Promise of Creativity

### 20231024_exploration
- where Consumers Diverge from Others- Identity Signaling and Product Domains
- kahn-et-al-1986-measuring-variety-seeking-and-reinforcement-behaviors-using-panel-data
- When to Trust Your Simulator- Dynamics-Aware Hybrid Offline-and-Online Reinforcement Learning
- What Out-of-distribution Is and Is Not
- The Effects of Diversity in Algorithmic Recommendations on Digital Content Consumption- A Field Experiment
- Robust On-Policy Sampling for Data-Efficient Policy Evaluation in Reinforcement Learning
- Offline Reinforcement Learning- Tutorial, Review, and Perspectives on Open Problems
- Off-Policy Deep Reinforcement Learning without Exploration
- Model-Based Reinforcement Learning with Nearly Tight Exploration Complexity Bounds
- Doubly Robust Policy Evaluation and Learning
- Counterfactual Reasoning and Learning Systems- The Example of Computational Advertising

### 20231011_Fairness_Algo
- Reducing Interference Bias in AB Tests of Ranking Algorithms
- Disparate Impact of Artificial Intelligence Bias in Ridehailing Economy’s Price Discrimination Algorithms
- Apparent Algorithmic Discrimination and Real-Time  Algorithmic Learnin
- Algorithmic Bias An Empirical Study of Apparent Gender-based Discrimination in the Display of STEM Career Ads

### 20230928_recommendationSys
- why people skip music
- When Fairness meets Bias- a Debiased Framework for Fairness aware Top-N Recommendation
- Values of User Exploration in Recommender Systems
- Towards Robust Fairness-aware Recommendation
- Towards Open-World Recommendation- An Inductive Model-based Collaborative Filtering Approach
- Surrogate for Long-Term User Experience in Recommender Systems
- Surrogate for Long-Term User Experience in Recommender Systems 2023-11-01 16_17_20
- Recommending for a Multi-sided Marketplace A Multi-Objective Hierarchical Approach
- Recency Dropout for Recurrent Recommender Systems
- RLAIF- Scaling Reinforcement Learning from Human Feedback with AI Feedback
- LearningtoRankfor InformationRetrieval
- How do successful scholars get their best research ideas

### 20230914_GNN
- Variational Graph Auto-Encoders
- NEURAL RELATIONAL INFERENCE WITH NODE-SPECIFIC INFORMATION
- Link Prediction Based on Graph Neural Networks
- Learnable Graph Convolutional Attention Networks
- Deepwalk Online learning of social representations

### 20230829_Fairness
- graph_convolution_network_base
- Toward Pareto Efficient Fairness-Utility Trade-off in Recommendation 
- Shin Oblander JMP draft
- Policy Optimization with Advantage Regularization for Long-Term Fairness in Decision Systems
- Fairness in Matching under Uncertainty
- Fairness and Abstractions in Sociotechnical Systems
- Disentangling and Operationalizing AI Fairness at LinkedIn
- Discrimination through Optimization- How Facebook’s Ad Delivery Can Lead to Biased Outcomes
- Discrimination through Image Selection by Job Advertisers on Facebook
- Controlling Fairness and Bias in Dynamic Learning-to-Rank

### 20230801_MDP
- Using Big Data to Model Time-Varying Effects for Marketing Resource (Re)Allocation
- Timeseries in MKT
- Sparse Sinkhorn Attention
- Morphing for Consumer Dynamics- Bandits Meet Hidden Markov Models
- Modelling Retail Customer Behavior at Merrill Lynch
- Modeling Marketing Dynamics by Time Series Econometrics
- MODELING CUSTOMER RELATIONSHIPS AS MARKOV CHAINS
- LightGBM- A Highly Efficient Gradient Boosting Decision Tree
- Language Models are Few-Shot Learners
- Improving Language Understanding by Generative Pre-Training
- Herding Learning and Incentives for Online Reviews
- Effects of Word-of-Mouth Versus Traditional Marketing Findings from an Internet Social Networking Site
- Dynamic discrete choice structural models- A survey
- Dynamic Allocation of Pharmaceutical Detailing and Sampling for Long-Term Profitability
- Comments on the Origin and Application of Markov Decision Processes
- Attention mechanisms in computer vision A survey
- A Survey on Evaluation of Large Language Models
- A Joint Model of Usage and Churn in Contractual Settings
- A General Survey on Attention Mechanisms in Deep Learning

### 20230601_demand
- Microeconometric models of consumer demand
- Assessing Consumer Demand with Noisy Neural Measurements

### 20230314_creativity
- What can quantitative measures of semantic distance tell us about creativity
- Toubia, Berger and Eliashberg 2021
- Toubia 2021
- The Cambridge Handbook of the Neuroscience of Creativity-Cambridge University Press (2018)
- Semantic Distance- An Automated Measure of Creativity That Is Novel and Appropriate
- Idea Generation Creativity and Prototypicality
- Extracting Features of Entertainment Products Guided LDA
- Can AI Help in Ideation- A Theory-Based Model for Idea Screening in Crowdsourcing Contests
- Automating creativity assessment with SemDis - An open platform for computing semantic distance
- Assessing Associative Distance Among Ideas Elicited by Tests of Divergent Thinking

